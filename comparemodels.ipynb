{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import load\n",
    "import numpy as np\n",
    "rf = load('models/rf_medium_model.joblib')\n",
    "kn = load('models/KN_medium_model.joblib')\n",
    "svm = load('models/svm_medium_model.joblib')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "XX = np.load('X_medium.npy', allow_pickle=True)\n",
    "yy = np.load('y_medium.npy', allow_pickle=True)\n",
    "np.nan_to_num(XX,0)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(XX, yy, test_size=0.2, random_state=42, stratify=yy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ahmed\\AppData\\Roaming\\Python\\Python312\\site-packages\\joblib\\externals\\loky\\backend\\context.py:136: UserWarning: Could not find the number of physical cores for the following reason:\n",
      "found 0 physical cores < 1\n",
      "Returning the number of logical cores instead. You can silence this warning by setting LOKY_MAX_CPU_COUNT to the number of cores you want to use.\n",
      "  warnings.warn(\n",
      "  File \"C:\\Users\\ahmed\\AppData\\Roaming\\Python\\Python312\\site-packages\\joblib\\externals\\loky\\backend\\context.py\", line 282, in _count_physical_cores\n",
      "    raise ValueError(f\"found {cpu_count_physical} physical cores < 1\")\n"
     ]
    }
   ],
   "source": [
    "# Predict the genre for each test sample\n",
    "rf_predictions = rf.predict(X_test)\n",
    "svm_predictions = svm.predict(X_test)\n",
    "kn_predictions = kn.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import numpy as np\n",
    "\n",
    "all_predictions = np.vstack([rf_predictions, svm_predictions, kn_predictions]).T\n",
    "\n",
    "final_predictions = []\n",
    "weights = [0.4, 0.4, 0.2]\n",
    "weighted_predictions = []\n",
    "for row in all_predictions:\n",
    "    weighted_vote_counts = Counter()\n",
    "    for model_prediction, weight in zip(row, weights):\n",
    "        weighted_vote_counts[model_prediction] += weight\n",
    "\n",
    "    # Choose the genre with the highest weighted vote count\n",
    "    majority_vote = weighted_vote_counts.most_common(2)[0][0]\n",
    "    #print(majority_vote)\n",
    "    weighted_predictions.append(majority_vote)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble Accuracy: 61.13%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Evaluate the ensemble's performance\n",
    "accuracy = accuracy_score(y_test, weighted_predictions)\n",
    "print(f'Ensemble Accuracy: {accuracy * 100:.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hip-Hop', 'Electronic', 'Experimental']\n"
     ]
    }
   ],
   "source": [
    "from datapreprosessing import * \n",
    "def classify_genre(audio_path):\n",
    "    geners =[]\n",
    "    features = extract_features(audio_path) \n",
    "    features = features.reshape(1, -1)\n",
    "    geners.append(rf.predict(features)[0])\n",
    "    geners.append(kn.predict(features)[0])\n",
    "    geners.append(svm.predict(features)[0])\n",
    "    return geners\n",
    "\n",
    "d = classify_genre('fma_small/000/000002.mp3')\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 52)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ahmed\\Desktop\\MusicInformatics\\project\\Music-Genre-Classification\\datapreprosessing.py:21: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  y, sr = librosa.load(audio_file, sr=None, mono=True)\n",
      "C:\\Users\\ahmed\\AppData\\Roaming\\Python\\Python312\\site-packages\\librosa\\core\\audio.py:184: FutureWarning: librosa.core.audio.__audioread_load\n",
      "\tDeprecated as of librosa version 0.10.0.\n",
      "\tIt will be removed in librosa version 1.0.\n",
      "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing fma_medium\\001\\001486.mp3: \n",
      "Error processing fma_medium\\005\\005574.mp3: \n",
      "Processed 10000 files so far\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ahmed\\AppData\\Roaming\\Python\\Python312\\site-packages\\librosa\\core\\pitch.py:101: UserWarning: Trying to estimate tuning from empty frequency set.\n",
      "  return pitch_tuning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 18000 files so far\n",
      "Processed 22000 files so far\n",
      "Processed 25000 files so far\n",
      "Processed 30000 files so far\n",
      "Processed 32000 files so far\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ahmed\\Desktop\\MusicInformatics\\project\\Music-Genre-Classification\\datapreprosessing.py:14: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "  np.min(feature), skew(feature),\n",
      "c:\\Users\\ahmed\\Desktop\\MusicInformatics\\project\\Music-Genre-Classification\\datapreprosessing.py:15: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "  kurtosis(feature),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 52000 files so far\n",
      "Processed 65000 files so far\n",
      "Error processing fma_medium\\065\\065753.mp3: \n",
      "Processed 67000 files so far\n",
      "Processed 79000 files so far\n",
      "Processed 80000 files so far\n",
      "Error processing fma_medium\\080\\080391.mp3: \n",
      "Error processing fma_medium\\098\\098558.mp3: \n",
      "Error processing fma_medium\\098\\098559.mp3: \n",
      "Error processing fma_medium\\098\\098560.mp3: \n",
      "Error processing fma_medium\\098\\098565.mp3: \n",
      "Error processing fma_medium\\098\\098566.mp3: \n",
      "Error processing fma_medium\\098\\098567.mp3: \n",
      "Error processing fma_medium\\098\\098568.mp3: \n",
      "Error processing fma_medium\\098\\098569.mp3: \n",
      "Error processing fma_medium\\098\\098571.mp3: \n",
      "Processed 99000 files so far\n",
      "Error processing fma_medium\\099\\099134.mp3: \n",
      "Error processing fma_medium\\105\\105247.mp3: \n",
      "Error processing fma_medium\\108\\108925.mp3: \n",
      "Processed 112000 files so far\n",
      "Processed 115000 files so far\n",
      "Processed 118000 files so far\n",
      "Processed 122000 files so far\n",
      "Processed 123000 files so far\n",
      "Processed 125000 files so far\n",
      "Error processing fma_medium\\126\\126981.mp3: \n",
      "Error processing fma_medium\\127\\127336.mp3: \n",
      "Processed 131000 files so far\n",
      "Error processing fma_medium\\133\\133297.mp3: \n",
      "Processed 140000 files so far\n",
      "Error processing fma_medium\\143\\143992.mp3: \n",
      "Processed 146000 files so far\n",
      "Processed 155000 files so far\n"
     ]
    }
   ],
   "source": [
    "from datapreprosessing import *\n",
    "audio_dir='fma_medium'\n",
    "\n",
    "#process_dataset(audio_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
